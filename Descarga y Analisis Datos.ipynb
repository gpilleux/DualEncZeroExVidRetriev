{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Descarga y Analisis Datos.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python2","display_name":"Python 2"}},"cells":[{"cell_type":"markdown","metadata":{"id":"HXePFDMa84Mc","colab_type":"text"},"source":["# **Descarga y Análisis de Datos + Dataloader**\n"]},{"cell_type":"code","metadata":{"id":"yUtBByZpeobv","colab_type":"code","outputId":"cc729312-44ea-462a-ace2-7b80d3d50a02","executionInfo":{"status":"ok","timestamp":1572365543988,"user_tz":180,"elapsed":2968,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"colab":{"base_uri":"https://localhost:8080/","height":143}},"source":["import os\n","import pickle\n","\n","if not os.path.exists('/content/dual_encoding'):\n","  !git clone https://github.com/danieljf24/dual_encoding.git\n","  "],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'dual_encoding'...\n","remote: Enumerating objects: 27, done.\u001b[K\n","remote: Counting objects: 100% (27/27), done.\u001b[K\n","remote: Compressing objects: 100% (24/24), done.\u001b[K\n","remote: Total 169 (delta 5), reused 22 (delta 3), pack-reused 142\u001b[K\n","Receiving objects: 100% (169/169), 307.21 KiB | 10.97 MiB/s, done.\n","Resolving deltas: 100% (58/58), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"y3w7FArtMoSd","colab_type":"text"},"source":["## Descargar MSR-VTT Dataset y Word2Vec"]},{"cell_type":"code","metadata":{"id":"yIljTerRe2_g","colab_type":"code","colab":{}},"source":["#Ejecutar para descargar los datos\n","%cd /content\n","\n","# download and extract dataset\n","!wget http://lixirong.net/data/cvpr2019/msrvtt10k-text-and-resnet-152-img1k.tar.gz\n","!tar zxf msrvtt10k-text-and-resnet-152-img1k.tar.gz\n","\n","# download and extract pre-trained word2vec\n","!wget http://lixirong.net/data/w2vv-tmm2018/word2vec.tar.gz\n","!tar zxf word2vec.tar.gz"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3A96ba5UUTOp","colab_type":"code","outputId":"6228b384-210b-4b71-9d2c-787e841d4d58","executionInfo":{"status":"ok","timestamp":1572365569402,"user_tz":180,"elapsed":24439,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"76b907b3-ca38-462b-ba4c-3e4f2c4af3bb","executionInfo":{"status":"ok","timestamp":1572365927185,"user_tz":180,"elapsed":354208,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"id":"Ncz_XnIxVF1y","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["#Ejecutar sólo si se tiene el dataset almacenado en un drive local\n","%cd /content/drive/My\\ Drive/FCFM/Deep\\ Learning/Proyecto\n","\n","# extraer dataset desde local\n","!tar zxf msrvtt10k-text-and-resnet-152-img1k.tar.gz -C /content/dual_encoding\n","\n","# extraer W2V desde local\n","!tar zxf word2vec.tar.gz -C /content/dual_encoding"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/FCFM/Deep Learning/Proyecto\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bk1UpwSvR1PB","colab_type":"text"},"source":["## Extraer el Vocabulario\n"]},{"cell_type":"code","metadata":{"id":"7alxXRBYtwfv","colab_type":"code","outputId":"0efab84a-f0bb-4541-c1eb-c51838e26cfe","executionInfo":{"status":"ok","timestamp":1572365940366,"user_tz":180,"elapsed":6654,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"colab":{"base_uri":"https://localhost:8080/","height":395}},"source":["%cd /content/dual_encoding\n","\n","trainCollection = 'msrvtt10ktrain'\n","valCollection = 'msrvtt10kval'\n","rootpath = '/content/dual_encoding'\n","\n","threshold=5\n","overwrite=0\n","\n","#Extraer vocabulario del training set\n","text_styles = ['bow', 'rnn']\n","for text_style in text_styles:\n","  !python util/vocab.py --rootpath $rootpath $trainCollection --threshold $threshold --text_style $text_style --overwrite $overwrite\n","  "],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/dual_encoding\n","{\n","  \"threshold\": 5, \n","  \"text_style\": \"bow\", \n","  \"rootpath\": \"/content/dual_encoding\", \n","  \"collection\": \"msrvtt10ktrain\", \n","  \"overwrite\": 0\n","}\n","130260/130260 [==============================] - 1s 10us/step\n","[29 Oct 16:18:56 - vocab.py:line 110] Saved vocabulary file to /content/dual_encoding/msrvtt10ktrain/TextData/vocabulary/bow/word_vocab_5.pkl\n","[29 Oct 16:18:56 - vocab.py:line 116] Saved vocabulary counter file to /content/dual_encoding/msrvtt10ktrain/TextData/vocabulary/bow/word_vocab_counter_5.txt\n","{\n","  \"threshold\": 5, \n","  \"text_style\": \"rnn\", \n","  \"rootpath\": \"/content/dual_encoding\", \n","  \"collection\": \"msrvtt10ktrain\", \n","  \"overwrite\": 0\n","}\n","130260/130260 [==============================] - 1s 10us/step\n","[29 Oct 16:18:59 - vocab.py:line 110] Saved vocabulary file to /content/dual_encoding/msrvtt10ktrain/TextData/vocabulary/rnn/word_vocab_5.pkl\n","[29 Oct 16:18:59 - vocab.py:line 116] Saved vocabulary counter file to /content/dual_encoding/msrvtt10ktrain/TextData/vocabulary/rnn/word_vocab_counter_5.txt\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"e54UcAmlM4AJ","colab_type":"text"},"source":["## Importar esenciales para cargar data"]},{"cell_type":"code","metadata":{"id":"yIiDhpZNg4A9","colab_type":"code","outputId":"d738fcc6-b413-4b2e-9e7b-e537a79d10aa","executionInfo":{"status":"ok","timestamp":1572365953284,"user_tz":180,"elapsed":5431,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["%cd /content/dual_encoding/util\n","\n","import data_provider as data\n","from text2vec import get_text_encoder\n","from basic.bigfile import BigFile\n","from vocab import Vocabulary\n","\n","%cd ..\n","\n","from model import get_model, get_we_parameter\n","from basic.util import read_dict\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["/content/dual_encoding/util\n","/content/dual_encoding\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VVqHwYWLPLh6","colab_type":"text"},"source":["## Carga de data"]},{"cell_type":"code","metadata":{"id":"pN81j91TR8N4","colab_type":"code","outputId":"263b514c-b6ca-45b1-8012-6a1eb46631c4","executionInfo":{"status":"ok","timestamp":1572381389206,"user_tz":180,"elapsed":6911,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["visual_feature = 'resnet-152-img1k-flatten0_outputos'\n","vocab = 'word_vocab_5'\n","\n","# collections: trian, val\n","collections = {'train': trainCollection, 'val': valCollection}\n","cap_file = {'train': '%s.caption.txt'%trainCollection, \n","            'val': '%s.caption.txt'%valCollection}\n","# caption\n","caption_files = { x: os.path.join(rootpath, collections[x], 'TextData', cap_file[x])\n","                    for x in collections }\n","\n","# Load visual features\n","visual_feat_path = {x: os.path.join(rootpath, collections[x], 'FeatureData', visual_feature)\n","                    for x in collections }\n","visual_feats = {x: BigFile(visual_feat_path[x]) for x in visual_feat_path}\n","\n","visual_feat_dim = visual_feats['train'].ndims\n","\n","# set bow vocabulary and encoding\n","bow_vocab_file = os.path.join(rootpath, trainCollection, 'TextData', 'vocabulary', 'bow', vocab+'.pkl')\n","bow_vocab = pickle.load(open(bow_vocab_file, 'rb'))\n","bow2vec = get_text_encoder('bow')(bow_vocab)\n","bow_vocab_size = len(bow_vocab)\n","\n","# set rnn vocabulary \n","rnn_vocab_file = os.path.join(rootpath, trainCollection, 'TextData', 'vocabulary', 'rnn', vocab+'.pkl')\n","rnn_vocab = pickle.load(open(rnn_vocab_file, 'rb'))\n","vocab_size = len(rnn_vocab)\n","\n","w2v_data_path = os.path.join(rootpath, \"word2vec\", 'flickr', 'vec500flickr30m')\n","we_parameter = get_we_parameter(rnn_vocab, w2v_data_path)\n","\n","'''# mapping layer structure'''\n","\n","video2frames = {x: read_dict(os.path.join(rootpath, collections[x], 'FeatureData', visual_feature, 'video2frames.txt'))\n","                for x in collections }"],"execution_count":43,"outputs":[{"output_type":"stream","text":["[BigFile] 305462x2048 instances loaded from /content/dual_encoding/msrvtt10ktrain/FeatureData/resnet-152-img1k-flatten0_outputos\n","[BigFile] 305462x2048 instances loaded from /content/dual_encoding/msrvtt10kval/FeatureData/resnet-152-img1k-flatten0_outputos\n"],"name":"stdout"},{"output_type":"stream","text":["[29 Oct 20:36:23 - text2vec.py:line 13] text2vec.py.Bow2Vec initializing ...\n"],"name":"stderr"},{"output_type":"stream","text":["[BigFile] 1743364x500 instances loaded from /content/dual_encoding/word2vec/flickr/vec500flickr30m\n","('getting pre-trained parameter for word embedding initialization', (7811, 500))\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"igLV3GfdPAs-","colab_type":"text"},"source":["## Generar Dataloader"]},{"cell_type":"code","metadata":{"id":"1X8by6lFcbv7","colab_type":"code","colab":{}},"source":["batch_size = 128\n","workers = 5\n","n_caption = 20\n","\n","# set data loader\n","data_loaders = data.get_data_loaders(\n","    caption_files, visual_feats, rnn_vocab, bow2vec, batch_size, workers, n_caption, video2frames=video2frames)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-EHrr0QiCBq0","colab_type":"text"},"source":["### Estructura de Dataloader"]},{"cell_type":"code","metadata":{"id":"ydqzgTIlpd27","colab_type":"code","outputId":"44a1b80f-7c5d-4a8f-ffba-960a6dd3f90b","executionInfo":{"status":"ok","timestamp":1572378259093,"user_tz":180,"elapsed":4463,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"colab":{"base_uri":"https://localhost:8080/","height":305}},"source":["train_loader = data_loaders['train']\n","\n","print(\"Estructura de un elemento del Dataloader\")\n","print('Dataloader: {}'.format(type(train_loader)))\n","for i, train_data in enumerate(train_loader):\n","  if i > 0:\n","    break  \n","  captions, videos, b2v, v, v2f = train_data\n","  print('Len train_data: {}, {}'.format(len(train_data), type(train_data)))\n","  for j in range(len(train_data) - 3):\n","    print('Len train_data[{}]: {}, {}'.format(j, len(train_data[j]), type(train_data[j])))\n","    for k in range(len(train_data[j])):\n","      print('Len train_data[{}][{}]: {}, {}'.format(j, k, len(train_data[j][k]), type(train_data[j][k])))\n","  print('Len train_data[{}]: {}, {} de {}'.format(2, len(train_data[2]), type(train_data[2]), type(train_data[2][0])))\n","  print('Len train_data[{}]: {}, {} de {}'.format(3, len(train_data[3]), type(train_data[3]), type(train_data[3][0])))\n","  print('Len train_data[{}]: {}, {} de {}'.format(4, len(train_data[4]), type(train_data[4]), type(train_data[4][0])))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Estructura de un elemento del Dataloader\n","Dataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n","Len train_data: 5, <type 'tuple'>\n","Len train_data[0]: 4, <type 'tuple'>\n","Len train_data[0][0]: 128, <class 'torch.Tensor'>\n","Len train_data[0][1]: 128, <class 'torch.Tensor'>\n","Len train_data[0][2]: 128, <type 'list'>\n","Len train_data[0][3]: 128, <class 'torch.Tensor'>\n","Len train_data[1]: 4, <type 'tuple'>\n","Len train_data[1][0]: 128, <class 'torch.Tensor'>\n","Len train_data[1][1]: 128, <class 'torch.Tensor'>\n","Len train_data[1][2]: 128, <type 'list'>\n","Len train_data[1][3]: 128, <class 'torch.Tensor'>\n","Len train_data[2]: 128, <type 'tuple'> de <type 'int'>\n","Len train_data[3]: 128, <type 'tuple'> de <type 'str'>\n","Len train_data[4]: 128, <type 'tuple'> de <type 'str'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6d-uIIOOuQby","colab_type":"text"},"source":["## Análisis del Vocabulario"]},{"cell_type":"code","metadata":{"id":"sHzsDpM3HH75","colab_type":"code","outputId":"137e7781-cf47-4c82-ec8f-615ab547d997","executionInfo":{"status":"ok","timestamp":1572323425573,"user_tz":180,"elapsed":574,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["print('Cantidad de palabras del BoW: {}'.format(bow_vocab_size))\n","print('Cantidad de palabras del RNN: {}'.format(vocab_size))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cantidad de palabras del BoW: 7807\n","Cantidad de palabras del RNN: 7811\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RqzSGjg-x5BD","colab_type":"text"},"source":["El vocabulario está compuesto por 7807 palabras. Vemos que en el caso del vocabulario del RNN, tiene 4 palabras agregadas que vienen siendo las palabras que denotan a las oraciones: \\<pad>, \\<start>, \\<end>, \\<unk>."]},{"cell_type":"markdown","metadata":{"id":"b7vHkYIe6zVu","colab_type":"text"},"source":["## Análisis de captions en training, validation y testing sets"]},{"cell_type":"markdown","metadata":{"id":"3EMb-tIZ7wvQ","colab_type":"text"},"source":["### Training Set"]},{"cell_type":"code","metadata":{"id":"AyAIaXm5zEnT","colab_type":"code","colab":{}},"source":["#Training set\n","print('Análisis Training Set')\n","\n","train_caption_path = caption_files['train']\n","train_caption = open(train_caption_path, 'r')\n","tc_cnt = 0\n","tc_dict = {}\n","\n","train_line = train_caption.readline().split('#')[0]\n","while train_line:\n","  try:\n","    tc_dict[line] += 1\n","  except:\n","    tc_dict[line] = 1\n","  tc_cnt += 1\n","  train_line = train_caption.readline().split('#')[0]\n","    \n","key_max = max(tc_dict.keys(), key=(lambda k: tc_dict[k]))\n","key_min = min(tc_dict.keys(), key=(lambda k: tc_dict[k]))\n","print(\"Cantidad de captions en training set: {}\".format(tc_cnt))\n","print(\"Máxima cantidad de captions de algún video: {}\".format(tc_dict[key_max]))\n","print(\"Mínima cantidad de captions de algún video: {}\".format(tc_dict[key_min]))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zZcqW3IW71DM","colab_type":"text"},"source":["### Validation Set"]},{"cell_type":"code","metadata":{"id":"a6XMapMf0_x8","colab_type":"code","colab":{}},"source":["#Validation set\n","print('Análisis Validation Set')\n","\n","val_caption_path = caption_files['val']\n","val_caption = open(val_caption_path, 'r')\n","vc_cnt = 0\n","vc_dict = {}\n","val_line = val_caption.readline().split('#')[0]\n","while val_line:\n","  try:\n","    vc_dict[line] += 1\n","  except:\n","    vc_dict[line] = 1\n","  vc_cnt += 1\n","  val_line = val_line.readline().split('#')[0]\n","    \n","key_max = max(vc_dict.keys(), key=(lambda k: vc_dict[k]))\n","key_min = min(vc_dict.keys(), key=(lambda k: vc_dict[k]))\n","print(\"Cantidad de captions en validation set: {}\".format(vc_cnt))\n","print(\"Máxima cantidad de captions de algún video: {}\".format(vc_dict[key_max]))\n","print(\"Mínima cantidad de captions de algún video: {}\".format(vc_dict[key_min]))\n","val_caption.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OVwSaLZ072rP","colab_type":"text"},"source":["### Testing Set"]},{"cell_type":"code","metadata":{"id":"faTTBuBg7dJN","colab_type":"code","colab":{}},"source":["#Testing set\n","print('Análisis Testing Set')\n","\n","test_caption_path = '/content/dual_encoding/'\n","test_caption = open(test_caption_path, 'r')\n","test_cnt = 0\n","test_dict = {}\n","test_line = test_caption.readline().split('#')[0]\n","while test_line:\n","  try:\n","    test_dict[line] += 1\n","  except:\n","    test_dict[line] = 1\n","  test_cnt += 1\n","  test_line = val_line.readline().split('#')[0]\n","    \n","key_max = max(test_dict.keys(), key=(lambda k: test_dict[k]))\n","key_min = min(test_dict.keys(), key=(lambda k: test_dict[k]))\n","print(\"Cantidad de captions en validation set: {}\".format(vc_cnt))\n","print(\"Máxima cantidad de captions de algún video: {}\".format(test_dict[key_max]))\n","print(\"Mínima cantidad de captions de algún video: {}\".format(test_dict[key_min]))\n","test_caption.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PVCZMoLXHqKa","colab_type":"text"},"source":["## Análisis W2V"]},{"cell_type":"code","metadata":{"id":"LPl59eJVG84O","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"630d99e7-e5cc-4eb9-ea75-c6cec45ea792","executionInfo":{"status":"ok","timestamp":1572380143420,"user_tz":180,"elapsed":3080,"user":{"displayName":"Guillermo Pilleux","photoUrl":"","userId":"03272588046346337095"}}},"source":["import numpy as np\n","#rnn_vocab, w2v_data_path\n","w2v_reader = BigFile(w2v_data_path)\n","print('Tamaño del embedding: {}'.format(w2v_reader.shape()))\n","ndims = w2v_reader.ndims\n","\n","we = []\n","for i in range(len(rnn_vocab)):\n","  #if i > 0:\n","    #break\n","  try:\n","      vec = w2v_reader.read_one(rnn_vocab.idx2word[i])\n","  except:\n","      vec = np.random.uniform(-1, 1, ndims)\n","  we.append(vec)\n","  \n","print('Tamaño vocabulario: {}'.format(len(we)))\n","print('Tamaño del vector representativo de cada palabra: {}'.format(len(we[0])))\n"],"execution_count":42,"outputs":[{"output_type":"stream","text":["[BigFile] 1743364x500 instances loaded from /content/dual_encoding/word2vec/flickr/vec500flickr30m\n","Tamaño del embedding: [1743364, 500]\n","Tamaño vocabulario: 7811\n","Tamaño del vector representativo de cada palabra: 500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vf-5tiPcJaNp","colab_type":"text"},"source":["Vemos que se cargan 1.743.364 de instancias del archivo W2V, donde cada instancia es un vector de dimensión 500 que representa una palabra."]},{"cell_type":"code","metadata":{"id":"Ej4dWkndHP6C","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}